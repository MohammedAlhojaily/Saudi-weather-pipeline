# ğŸŒ¦ï¸ Saudi Weather Data Pipeline â€” Airflow, Docker, PostgreSQL & Metabase

This project is a fully containerized ETL data pipeline that collects daily weather data for major Saudi Arabian cities using the OpenWeatherMap API.
The data is processed and stored automatically through Apache Airflow, saved into PostgreSQL, and visualized using Metabase.


---

## ğŸ› ï¸ Tech Stack

**Airflow** â€” Workflow orchestration

**PostgreSQL** â€” Weather data storage

**Docker** â€” Infrastructure & service management

**Metabase** â€” Dashboards & data exploration

**pgAdmin** â€” Database GUI for development

---

## ğŸ” Project Overview

This pipeline automatically:
- Fetches up-to-date weather information (temperature, humidity, description, etc.)
- Covers 10 major cities in Saudi Arabia
- Inserts the data into a PostgreSQL table
- Runs daily through an Airflow DAG
- Enables dashboard creation using Metabase

---

## âœ¨ Project Visualization (Metabase Dashboard)

The final output is visualized in a Metabase dashboard, showing key weather metrics collected by the pipeline.
<p align="center">
  <img src="images/saudi_weather_analysis.png" alt="Saudi Weather Analysis" width="75%" height="75%">
</p>

---

## ğŸš€ Getting Started

Follow the steps below to run the project locally.

1. **Clone the repository**
   ```bash
   git clone https://github.com/MohammedAlhojaily/Saudi-weather-pipeline.git
   cd weather-data-pipeline

2. **Create an environment file**
   ```bash
   cp .env.example .env

Then edit .env and add:
Your OpenWeatherMap API key Database usernames/passwords of your choice
You can generate your API key here: [here](https://openweathermap.org/current). 

3. **Start the services**
   ```bash
   docker compose up --build

4. **Access the tools**
- **Airflow:** http://localhost:8080
- **pgAdmin:** http://localhost:5050
- **Metabase:** http://localhost:3000

## ğŸ‰ Completion
You now have a fully automated Saudi Weather ETL Pipeline.

## ğŸ‘¤ Author
This project was customized and built by Mohammed Alhojaily.
